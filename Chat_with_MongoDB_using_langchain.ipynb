{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shwetabhgit/AIMODEL/blob/main/Chat_with_MongoDB_using_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b25b1bbe"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the necessary libraries for interacting with MongoDB using pip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a1bc2a8",
        "outputId": "d9dbc797-33bd-42c9-c6b7-e4e2c347e452"
      },
      "source": [
        "!pip install -q pymongo langchain-mongodb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/313.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VodlSnAEe_ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59f09dc7",
        "outputId": "72aca726-1801-4bbc-959b-c3def51c7864"
      },
      "source": [
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd # Import pandas as it's used by fetch_california_housing(as_frame=True)\n",
        "\n",
        "uri = \"mongodb+srv://shwetabhgenai:QDBJGvSospmA7FPZ@cluster0.zpo3dkn.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "\n",
        "# Create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "\n",
        "# Send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "\n",
        "    # Select the database and collection\n",
        "    db = client[\"mydatabase\"] # Replace \"mydatabase\" with your database name\n",
        "    collection = db[\"housing\"] # Replace \"housing\" with your desired collection name\n",
        "\n",
        "    # Load the California Housing dataset\n",
        "    california_housing_bunch = fetch_california_housing(as_frame=True)\n",
        "    california_housing_df = california_housing_bunch.frame\n",
        "\n",
        "    # Convert the pandas DataFrame to a list of dictionaries\n",
        "    data_to_insert = california_housing_df.to_dict(orient=\"records\")\n",
        "\n",
        "    # Insert the list of dictionaries into the MongoDB collection\n",
        "    # It's good practice to clear the collection before inserting if you run this multiple times\n",
        "    # collection.delete_many({}) # Uncomment this line if you want to clear the collection first\n",
        "    insert_result = collection.insert_many(data_to_insert)\n",
        "\n",
        "    print(f\"Inserted {len(insert_result.inserted_ids)} documents into the '{collection.name}' collection.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinged your deployment. You successfully connected to MongoDB!\n",
            "Inserted 20640 documents into the 'housing' collection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-generativeai langchain langchain-community langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlhZ54jWZ9XP",
        "outputId": "8a2c74a8-239a-45e4-d347-e8c7bb22db09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata # Import userdata\n",
        "import json # Import the json library to parse the generated query\n",
        "\n",
        "# Assuming 'db' is the MongoDB database object from the previous cell\n",
        "# and 'collection' is the 'housing' collection\n",
        "\n",
        "# Get collection info to provide schema context to the LLM\n",
        "# This is a simplified way; for complex schemas, you might need more detailed info\n",
        "# Ensure california_housing_df is accessible or load it again if necessary\n",
        "try:\n",
        "    collection_info = {\n",
        "        \"name\": collection.name,\n",
        "        \"columns\": list(california_housing_df.columns) # Using dataframe columns as a proxy for schema\n",
        "    }\n",
        "except NameError:\n",
        "    # If california_housing_df is not defined, load it here\n",
        "    from sklearn.datasets import fetch_california_housing\n",
        "    california_housing_bunch = fetch_california_housing(as_frame=True)\n",
        "    california_housing_df = california_housing_bunch.frame\n",
        "    collection_info = {\n",
        "        \"name\": collection.name,\n",
        "        \"columns\": list(california_housing_df.columns)\n",
        "    }\n",
        "\n",
        "\n",
        "# Define the prompt template for generating MongoDB queries\n",
        "# We instruct the LLM to generate a MongoDB find query or aggregation pipeline stages in JSON format.\n",
        "# Explicitly tell the LLM *not* to include markdown.\n",
        "mongo_query_template = \"\"\"\n",
        "You are an AI assistant that translates natural language questions into MongoDB find queries or aggregation pipeline stages.\n",
        "You will be given a user question and information about the MongoDB collection schema.\n",
        "Generate a valid MongoDB query that answers the question.\n",
        "If the question requires aggregation (like summing or grouping), generate an aggregation pipeline as a JSON list of dictionaries.\n",
        "If the question requires finding documents, generate a find query as a JSON dictionary.\n",
        "Do not include any extra text or markdown formatting, just the JSON dictionary or list representing the query.\n",
        "\n",
        "Collection Name: {collection_name}\n",
        "Available Fields: {collection_fields}\n",
        "\n",
        "User Question: {question}\n",
        "\n",
        "MongoDB Query:\n",
        "\"\"\"\n",
        "\n",
        "mongo_query_prompt = PromptTemplate(\n",
        "    input_variables=[\"collection_name\", \"collection_fields\", \"question\"],\n",
        "    template=mongo_query_template,\n",
        ")\n",
        "\n",
        "# Initialize the LLM\n",
        "# Get the API key from user data\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "llm = ChatGoogleGenerativeAI(google_api_key=GOOGLE_API_KEY, model=\"gemini-1.5-flash-latest\", temperature=0)\n",
        "\n",
        "# Create the chain to generate the MongoDB query string\n",
        "generate_mongo_query_chain = (\n",
        "    mongo_query_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# Example usage: Generate, execute, and display the result\n",
        "question = \"What is the total population?\"\n",
        "generated_query_string = generate_mongo_query_chain.invoke({\n",
        "     \"question\": question,\n",
        "     \"collection_name\": collection_info[\"name\"],\n",
        "     \"collection_fields\": \", \".join(collection_info[\"columns\"])\n",
        " })\n",
        "\n",
        "print(\"Generated MongoDB Query String (raw):\")\n",
        "print(generated_query_string)\n",
        "\n",
        "# --- Code to execute the generated query ---\n",
        "try:\n",
        "    # Clean the generated string by removing markdown code block fences\n",
        "    cleaned_query_string = generated_query_string.strip()\n",
        "    if cleaned_query_string.startswith(\"```json\"):\n",
        "        cleaned_query_string = cleaned_query_string[len(\"```json\"):].strip()\n",
        "    if cleaned_query_string.endswith(\"```\"):\n",
        "        cleaned_query_string = cleaned_query_string[:-len(\"```\")].strip()\n",
        "\n",
        "    print(\"\\nCleaned MongoDB Query String:\")\n",
        "    print(cleaned_query_string)\n",
        "\n",
        "    # Parse the cleaned query string as JSON\n",
        "    executable_query = json.loads(cleaned_query_string)\n",
        "\n",
        "    # Check if it's an aggregation pipeline (a list) or a find query (a dictionary)\n",
        "    if isinstance(executable_query, list):\n",
        "        # Execute aggregation pipeline\n",
        "        print(\"\\nExecuting Aggregation Pipeline...\")\n",
        "        results = list(collection.aggregate(executable_query))\n",
        "    elif isinstance(executable_query, dict):\n",
        "        # Execute find query\n",
        "        print(\"\\nExecuting Find Query...\")\n",
        "        # For a find query, the dictionary is the filter document\n",
        "        results = list(collection.find(executable_query)) # Pass the dictionary directly as the filter\n",
        "    else:\n",
        "        results = \"Invalid query format generated.\"\n",
        "\n",
        "    print(\"\\nQuery Result:\")\n",
        "    print(results)\n",
        "\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"\\nError decoding JSON query string: {e}\")\n",
        "    print(\"Generated string was:\", generated_query_string)\n",
        "    print(\"Cleaned string was:\", cleaned_query_string)\n",
        "except Exception as e:\n",
        "    print(f\"\\nError executing MongoDB query: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lb6xchVZCsw",
        "outputId": "baaa0f99-7ff6-4c9b-f12f-f7aea9ef7883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated MongoDB Query String (raw):\n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"$group\": {\n",
            "      \"_id\": null,\n",
            "      \"totalPopulation\": {\n",
            "        \"$sum\": \"$Population\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "```\n",
            "\n",
            "Cleaned MongoDB Query String:\n",
            "[\n",
            "  {\n",
            "    \"$group\": {\n",
            "      \"_id\": null,\n",
            "      \"totalPopulation\": {\n",
            "        \"$sum\": \"$Population\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "]\n",
            "\n",
            "Executing Aggregation Pipeline...\n",
            "\n",
            "Query Result:\n",
            "[{'_id': None, 'totalPopulation': 58843680.0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "oafNhTL3Y9TW"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}